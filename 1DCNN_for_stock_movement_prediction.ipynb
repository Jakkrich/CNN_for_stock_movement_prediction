{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1DCNN_for_stock_movement_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r85WfbuPaVS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive', force_remount=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEXhYYtgjBvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "!wget https://github.com/jetanaso/datasets/raw/master/S50IF_CON.xls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPEFhBaFi5kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import necessary libraries\n",
        "%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import load_model, Sequential, Model\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras import regularizers\n",
        "from tensorflow import set_random_seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3fdOGmBjlNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKSURsM3jBx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data preparation\n",
        "cols = ['Date','Open','High','Low','Close','Volume']\n",
        "df = pd.read_csv('S50IF_CON.xls', names=cols, index_col=False, skiprows=1, delimiter='\\t')\n",
        "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
        "df['Open'] = df['Open'].str.replace(',','').astype('float')\n",
        "df['High'] = df['High'].str.replace(',','').astype('float')\n",
        "df['Low'] = df['Low'].str.replace(',','').astype('float')\n",
        "df['Close'] = df['Close'].str.replace(',','').astype('float')\n",
        "df['Volume'] = df['Volume'].str.replace(',','').astype('float')\n",
        "df.set_index('Date', drop=True, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvQ97EDsjB2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = 88\n",
        "forecast_horizon = 22 \n",
        "\n",
        "dataset = df.copy()\n",
        "dataset['Open_binary'] = np.where(dataset['Open'].shift(1) < dataset['Open'], 1, 0)\n",
        "dataset['High_binary'] = np.where(dataset['High'].shift(1) < dataset['High'], 1, 0)\n",
        "dataset['Low_binary'] = np.where(dataset['Low'].shift(1) < dataset['Low'], 1, 0)\n",
        "dataset['Close_binary'] = np.where(dataset['Close'].shift(1) < dataset['Close'], 1, 0)\n",
        "dataset['Volume_binary'] = np.where(dataset['Volume'].shift(1) < dataset['Volume'], 1, 0)\n",
        "dataset['Label'] = np.where(dataset['Close'].shift(-forecast_horizon) > dataset['Close'], 1, 0)\n",
        "dataset = dataset.iloc[:-forecast_horizon]\n",
        "dataset.tail(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP6FV2KPjK6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define input sequence\n",
        "open = dataset['Open_binary'].values\n",
        "high = dataset['High_binary'].values\n",
        "low = dataset['Low_binary'].values\n",
        "close = dataset['Close_binary'].values\n",
        "volume = dataset['Volume_binary'].values\n",
        "label = dataset['Label'].values\n",
        "\n",
        "print(open, open.shape)\n",
        "print(high, high.shape)\n",
        "print(low, low.shape)\n",
        "print(close, close.shape)\n",
        "print(volume, volume.shape)\n",
        "print(label, label.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c82dHaKNjK-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to [rows, columns] structure\n",
        "open = open.reshape((len(open), 1))\n",
        "high = high.reshape((len(high), 1))\n",
        "low = low.reshape((len(low), 1))\n",
        "close = low.reshape((len(close), 1))\n",
        "volume = volume.reshape((len(volume), 1))\n",
        "label = label.reshape((len(label), 1))\n",
        "\n",
        "# horizontally stack columns\n",
        "dataset = np.hstack((open, high, low, close, volume, label))\n",
        "\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "y = to_categorical(y)\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "# summarize the data, for example\n",
        "for i in range(1):\n",
        "\tprint(X[i], y[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTo2pNhtjK8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split train/validate/test datasets (90:5:5)\n",
        "trainX = X[:int(X.shape[0]*.9),:] \n",
        "trainy = y[:int(X.shape[0]*.9)] \n",
        "validateX = X[int(X.shape[0]*.9):int(X.shape[0]*.95),:]\n",
        "validatey = y[int(X.shape[0]*.9):int(X.shape[0]*.95)]\n",
        "testX = X[int(X.shape[0]*.95):,:]\n",
        "testy = y[int(X.shape[0]*.95):]\n",
        "\n",
        "print(trainX.shape, trainy.shape)\n",
        "print(validateX.shape, validatey.shape)\n",
        "print(testX.shape, testy.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrBylf3zjB0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(trainX, trainy, validateX, validatey):\n",
        "  # define model architecture\n",
        "  n_features = X.shape[2]\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=24, kernel_size=5, activation='relu', \n",
        "                  kernel_regularizer=regularizers.l2(0.007), input_shape=(n_steps, n_features)))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Dropout(rate=0.35))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(50, activation='relu'))\n",
        "  model.add(Dropout(rate=0.15))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(optimizer='RMSprop', loss='mse', metrics=['accuracy'])\n",
        "  \n",
        "  model.summary\n",
        "\n",
        "  # fit model\n",
        "  history = model.fit(trainX, trainy, validation_data=(validateX, validatey), epochs=20, batch_size=16, verbose=0)\n",
        "\n",
        "  # plotting learning curve\n",
        "  plt.plot(history.history['loss'], label='train')\n",
        "  plt.plot(history.history['val_loss'], label='validate')\n",
        "  plt.title('Loss Development')\n",
        "  plt.xticks(np.arange(0,21,step=2))\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(history.history['acc'], label='train')\n",
        "  plt.plot(history.history['val_acc'], label='validate')\n",
        "  plt.title('Accuracy Development')\n",
        "  plt.xticks(np.arange(0,21,step=2))\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  return model\n",
        "\n",
        "################################################################################\n",
        "\n",
        "nums_model = 30\n",
        "for i in range(nums_model):\n",
        "\t# fit model\n",
        "\tmodel = fit_model(trainX, trainy, validateX, validatey)\n",
        "\t# save model\n",
        "\tfilename = '/drive/My Drive/Colab Notebooks/1dcnn_model_' + str(i+1) + '.h5'\n",
        "\tmodel.save(filename)\n",
        "\tprint('>Saved %s' % filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzsWaIUgkBAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_all_models(n_models):\n",
        "\tall_models = list()\n",
        "\tfor i in range(n_models):\n",
        "\t\tfilename = '/drive/My Drive/Colab Notebooks/1dcnn_model_' + str(i+1) + '.h5'\n",
        "\t\tmodel = load_model(filename)\n",
        "\t\tall_models.append(model)\n",
        "\t\tprint('>loaded %s' % filename)\n",
        "\treturn all_models\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# load all models at once\n",
        "members = load_all_models(num_models)\n",
        "print('Loaded %d models' % len(members))\n",
        "\n",
        "# evaluate standalone models on test dataset\n",
        "acc_list = []\n",
        "for i,model in enumerate(members):\n",
        "  _, acc = model.evaluate(testX, testy, verbose=0)\n",
        "  acc_list.append(acc)\n",
        "  print('Model#%s Accuracy on test dataset: %.3f%%' % (i+1, acc*100))\n",
        "print('='*42)\n",
        "print('Average 1DCNN Accuracy on test dataset: %.3f%%' % (np.mean(acc_list)*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2ZiCpJMXUYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_stacked_model(members):\n",
        "\t# update all layers in all models to not be trainable\n",
        "\tfor i in range(len(members)):\n",
        "\t\tmodel = members[i]\n",
        "\t\tfor layer in model.layers:\n",
        "\t\t\t# make not trainable\n",
        "\t\t\tlayer.trainable = False\n",
        "\t\t\t# rename to avoid 'unique layer name' issue\n",
        "\t\t\tlayer.name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
        "\t# define multi-headed input\n",
        "\tensemble_visible = [model.input for model in members]\n",
        "\t# concatenate merge output from each model\n",
        "\tensemble_outputs = [model.output for model in members]\n",
        "\tmerge = concatenate(ensemble_outputs)\n",
        "\thidden = Dense(60, activation='sigmoid')(merge)\n",
        "\toutput = Dense(2, activation='softmax')(hidden)\n",
        "\tmodel = Model(inputs=ensemble_visible, outputs=output)\n",
        "\t# plot graph of ensemble\n",
        "\tplot_model(model, show_shapes=True, to_file='/drive/My Drive/Colab Notebooks/model_graph.png')\n",
        "\t# compile\n",
        "\tmodel.compile(loss='mse', optimizer='RMSprop', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "def fit_stacked_model(model, inputX, inputy):\n",
        "\t# prepare input data\n",
        "\tX = [inputX for _ in range(len(model.input))]\n",
        "\t# fit model\n",
        "\tmodel.fit(X, inputy, epochs=30, verbose=0)\n",
        " \n",
        "def predict_stacked_model(model, inputX):\n",
        "\t# prepare input data\n",
        "\tX = [inputX for _ in range(len(model.input))]\n",
        "\t# make prediction\n",
        "\treturn model.predict(X, verbose=0)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# define ensemble model\n",
        "stacked_model = define_stacked_model(members)\n",
        "\n",
        "# fit stacked model on validate dataset\n",
        "fit_stacked_model(stacked_model, validateX, validatey)\n",
        "\n",
        "# make predictions and evaluate\n",
        "yhat = predict_stacked_model(stacked_model, testX)\n",
        "yhat = np.argmax(yhat, axis=1)\n",
        "acc = accuracy_score(np.argmax(testy, axis=1), yhat)\n",
        "print('Ensemble 1DCNN Accuracy on test dataset: %.3f%%' % (acc*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}